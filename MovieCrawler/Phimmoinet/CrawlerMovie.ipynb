{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTKQs1NZzsZV"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not os.path.exists('./datalake/my_folder'):\n",
        "   os.makedirs('./datalake/my_folder')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EowZfTaB3-S2"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ncz4hzTUyaAA"
      },
      "outputs": [],
      "source": [
        "# chunk_size = 100000  # Adjust the chunk size as per your system’s memory constraints\n",
        "# csv_file = url+'data/ml-latest/movies.csv'\n",
        "\n",
        "# df = pd.read_csv(csv_file)\n",
        "\n",
        "\n",
        "# set_genres = set()\n",
        "# for d in df['genres']:\n",
        "#   for stri in d.split('|'):\n",
        "#     set_genres.add(stri)\n",
        "# df_set = pd.DataFrame(list(set_genres))\n",
        "# df_set.to_csv(url + 'data/ml-latest/genres.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEfFzdw9cR_O"
      },
      "source": [
        "Crawl all Genre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcC9jsXAcPJx",
        "outputId": "323dec72-346b-4ccf-ae97-56b9769e2b39"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "# Địa chỉ URL cần lấy dữ liệu\n",
        "urlMovie = 'https://phimmoiiii.net/'\n",
        "\n",
        "# Lấy nội dung HTML từ URL\n",
        "response = requests.get(urlMovie)\n",
        "html_content = response.content\n",
        "\n",
        "# Phân tích HTML\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# Tìm tất cả các thẻ ul có class là 'sub-menu'\n",
        "sub_menu_ul = soup.find('ul', class_='sub-menu')\n",
        "\n",
        "list_genre = []\n",
        "\n",
        "# Nếu tìm thấy thẻ ul có class là 'sub-menu'\n",
        "if sub_menu_ul:\n",
        "    # Tìm tất cả các thẻ li trong thẻ ul 'sub-menu'\n",
        "    sub_menu_items = sub_menu_ul.find_all('li')\n",
        "\n",
        "    # Duyệt qua từng thẻ li\n",
        "    for item in sub_menu_items:\n",
        "        # Tìm thẻ a trong thẻ li\n",
        "        a_tag = item.find('a')\n",
        "        # Nếu tìm thấy thẻ a\n",
        "        if a_tag:\n",
        "            # Trích xuất href và nội dung của thẻ a\n",
        "            href = a_tag.get('href')\n",
        "            content = a_tag.text.strip()\n",
        "            list_genre.append([href, content])\n",
        "            print(f\"Link: {href}, Content: {content}\")\n",
        "else:\n",
        "    print(\"Không tìm thấy thẻ ul có class là 'sub-menu'\")\n",
        "\n",
        "df_genre = pd.DataFrame(list_genre, columns=['url', 'name'])\n",
        "df_genre.to_csv('./datalake/genre_vietnamese.csv',index=False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkixljcBmMI_"
      },
      "source": [
        "Crawle movie by year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2l66yLj3YF1P"
      },
      "outputs": [],
      "source": [
        "def crawlMovieByPage(page, url, year):\n",
        "    print(f'[START] Page {page}, year {year}: ')\n",
        "    list_movies = []\n",
        "    url_movie = url + '/{0}'.format(year) if page == 1 else url + '/{0}/page/{1}'.format(year, page)\n",
        "    # Lấy nội dung HTML từ URL\n",
        "    try:\n",
        "      response = requests.get(url_movie, timeout=10)\n",
        "    except requests.exceptions.Timeout:\n",
        "      print(\"Timed out\")\n",
        "      return False\n",
        "    if response.status_code > 300:\n",
        "       return False\n",
        "    html_content = response.content\n",
        "\n",
        "    # Phân tích HTML\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    # Tìm tất cả các thẻ div có class là 'items'\n",
        "    list_movie_div = soup.find('div', class_='items')\n",
        "\n",
        "    # Nếu tìm thấy thẻ ul có class là 'sub-menu'\n",
        "    if list_movie_div:\n",
        "        # Tìm tất cả các thẻ li trong thẻ ul 'sub-menu'\n",
        "        movie_items = list_movie_div.find_all('article')\n",
        "\n",
        "        # Duyệt qua từng thẻ li\n",
        "        for item in movie_items:\n",
        "            mv_img_url = ''\n",
        "            mv_vn_name = ''\n",
        "            mv_other_name = ''\n",
        "            mv_url = ''\n",
        "            mv_status = ''\n",
        "\n",
        "            try:\n",
        "              img_tag = item.find('img')\n",
        "              status_tag = item.find('div', class_='trangthai')\n",
        "              url_mv_div = item.select('div.data h3 a')[0]\n",
        "              name_or_div = item.select('div.data span span')[0]\n",
        "              # print(img_tag)\n",
        "              # print(status_tag)\n",
        "              # print(url_mv_div)\n",
        "              # print(name_en_div)\n",
        "\n",
        "              if img_tag:\n",
        "                mv_img_url = img_tag.get('src')\n",
        "              if status_tag:\n",
        "                mv_status = status_tag.text.strip()\n",
        "              if url_mv_div:\n",
        "                mv_vn_name = url_mv_div.text.strip()\n",
        "                mv_url = url_mv_div.get('href')\n",
        "              if name_or_div:\n",
        "                mv_other_name = name_or_div.text.strip()\n",
        "              print('  ', mv_vn_name, mv_other_name, mv_url, mv_img_url, mv_status)\n",
        "              list_movies.append([mv_vn_name, mv_other_name, mv_url, mv_img_url, mv_status])\n",
        "            except Exception as error:\n",
        "              print('[*] Error', error)\n",
        "              return False\n",
        "    if len(list_movies) > 0:\n",
        "      df_movies = pd.DataFrame(list_movies, columns=['name_vn', 'name_other', 'url','image','status'])\n",
        "      df_movies.index.name='id'\n",
        "      if not os.path.exists(f'./datalake/{year}'):\n",
        "        os.makedirs(f'./datalake/{year}')\n",
        "      df_movies.to_csv('./datalake/{year}/movie_page_{page}.csv'.format(year=year, page=page))\n",
        "      return True\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "year = 1990\n",
        "\n",
        "for i in range(1, 300):\n",
        "    if i >= 1:\n",
        "      is_success = crawlMovieByPage(i,'https://phimmoiiii.net/nam-phat-hanh',year)\n",
        "      if not(is_success):\n",
        "        print(f'Finish year {year}')\n",
        "        time.sleep(1)\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss8UMsbIYFi4"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxtK40Ck0PLt"
      },
      "outputs": [],
      "source": [
        "year = 1990\n",
        "\n",
        "while year <= 2024:\n",
        "  for i in range(1, 300):\n",
        "    if i >= 1:\n",
        "      is_success = crawlMovieByPage(i,'https://phimmoiiii.net/nam-phat-hanh',year)\n",
        "      if not(is_success):\n",
        "        print(f'Finish year {year}')\n",
        "        time.sleep(1)\n",
        "        break\n",
        "  year += 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5RGs3v9m5uF"
      },
      "outputs": [],
      "source": [
        "def getUrlVideoOfMovie(id):\n",
        "  url_ajax = 'https://phimmoiiii.net/wp-admin/admin-ajax.php'\n",
        "  payload = {'action': 'doo_player_ajax','type': 'movie','post': id, 'nume': 1 }\n",
        "  responseAjax = requests.post(url_ajax,data= payload)\n",
        "\n",
        "  if responseAjax.status_code == 200:\n",
        "    response_data = responseAjax.json()\n",
        "    embed_url = response_data.get('embed_url')\n",
        "    if embed_url:\n",
        "        return embed_url\n",
        "  else:\n",
        "    print('[ERROR] Fail to get the url video of movie id {}'.format(id))\n",
        "    return ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-VFfxXPw-ST",
        "outputId": "cbc1a4e8-f021-49b1-e8dd-38c9ed34f8a9"
      },
      "outputs": [],
      "source": [
        "# Crawl each movie by url\n",
        "\n",
        "def crawlMovieByUrl(url_movie):\n",
        "    # Lấy nội dung HTML từ URL\n",
        "    response = requests.get(url_movie)\n",
        "    html_content = response.content\n",
        "\n",
        "    movie_id = -1\n",
        "    movie_video_url = ''\n",
        "    movie_description = ''\n",
        "    movie_genres = []\n",
        "    movie_directors = []\n",
        "    movie_actors = []\n",
        "    movie_country = ''\n",
        "    movie_length = 0\n",
        "    movie_date = ''\n",
        "\n",
        "    # Phân tích HTML\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    # Data id and url of movie and video movie\n",
        "    input_post_id = soup.find(attrs={'name': 'postid'})\n",
        "    if input_post_id:\n",
        "      movie_id = int(input_post_id.get('value'))\n",
        "      movie_video_url = getUrlVideoOfMovie(movie_id)\n",
        "\n",
        "    # Data date\n",
        "    span_date = soup.find('span', attrs={'itemprop': 'dateCreated'})\n",
        "    if span_date:\n",
        "      movie_date = span_date.text.strip()\n",
        "\n",
        "    # Data time\n",
        "    span_time = soup.find('span', attrs={'itemprop': 'duration'})\n",
        "    if span_time:\n",
        "      movie_length = span_time.text.strip()\n",
        "\n",
        "    # Data country\n",
        "    span_country = soup.find('span', attrs={'class': 'country'})\n",
        "    if span_country:\n",
        "      movie_country = span_country.text.strip()\n",
        "\n",
        "    # Data description\n",
        "    span_description = soup.find('div', attrs={'itemprop': 'description'})\n",
        "    if span_description:\n",
        "      p_description = span_description.find('p')\n",
        "      if p_description:\n",
        "        movie_description = p_description.text.strip()\n",
        "\n",
        "    # Div genres\n",
        "    div_genres = soup.find('div', class_='sgeneros')\n",
        "    if div_genres:\n",
        "      list_genres_a = div_genres.find_all('a')\n",
        "      if(len(list_genres_a) > 0):\n",
        "        for a in list_genres_a:\n",
        "          movie_genres.append(a.text)\n",
        "\n",
        "    # Div directors\n",
        "    div_directors = soup.find_all('div', class_='person', attrs={'itemprop': 'director'})\n",
        "    if div_directors and len(div_directors) > 0:\n",
        "      for div_director in div_directors:\n",
        "        director_img = div_director.find('img')\n",
        "        director_data = div_director.find('a', attrs={'itemprop': 'url'})\n",
        "        director_img_url = ''\n",
        "        director_name = ''\n",
        "        director_type = div_director.get('itemtype')\n",
        "        if director_img:\n",
        "          director_img_url = director_img.get('href')\n",
        "        if director_data:\n",
        "          director_name = director_data.text\n",
        "        movie_directors.append({\n",
        "            'type': director_type,\n",
        "            'name': director_name,\n",
        "            'image': director_img_url\n",
        "        })\n",
        "    # Div actors\n",
        "    div_actors = soup.find_all('div', class_='person', attrs={'itemprop': 'actor'})\n",
        "    if div_actors and len(div_actors) > 0:\n",
        "      for div_actor in div_actors:\n",
        "        actor_img_url = ''\n",
        "        actor_name = ''\n",
        "        actor_character = ''\n",
        "        actor_type = div_actor.get('itemtype')\n",
        "        actor_img = div_actor.find('img')\n",
        "        div_actor_character = div_actor.find('div', class_='caracter')\n",
        "        div_actor_data = div_actor.find('a', attrs={'itemprop': 'url'})\n",
        "        if actor_img:\n",
        "          actor_img_url = actor_img.get('src')\n",
        "        if div_actor_data:\n",
        "          actor_name = div_actor_data.text\n",
        "        if div_actor_character:\n",
        "          actor_character = div_actor_character.text\n",
        "        movie_actors.append({\n",
        "            'type': actor_type,\n",
        "            'name': actor_name,\n",
        "            'image': actor_img_url,\n",
        "            'character': actor_character\n",
        "        })\n",
        "    # stringFormat = '[Data]: id: %d, img: %s, country: %s, length: %s, date: %s'\n",
        "    # print(stringFormat.format(movie_id, movie_video_url, movie_country, movie_length, movie_date))\n",
        "    # print(movie_description)\n",
        "    # print(movie_genres)\n",
        "    # print(movie_directors)\n",
        "    # print(movie_actors)\n",
        "\n",
        "    result = {\n",
        "        'movie_id': movie_id,\n",
        "        'movie_video': movie_video_url,\n",
        "        'movie_country': movie_country,\n",
        "        'movie_length': movie_length,\n",
        "        'movie_date': movie_date,\n",
        "        'movie_description': movie_description,\n",
        "        'movie_genres': movie_genres,\n",
        "        'movie_directors': movie_directors,\n",
        "        'movie_actors': movie_actors\n",
        "    }\n",
        "\n",
        "    return result\n",
        "\n",
        "test = crawlMovieByUrl('https://phimmoiiii.net/phim-le/quy-co-mang-nhen')\n",
        "print(test)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
